import streamlit as st
import streamlit.components.v1 as components
from urllib import parse
import requests
from bs4 import BeautifulSoup as bs
from datetime import datetime, timedelta
import clipboard
import random
import pandas as pd
import google_auth_httplib2
import httplib2
import pandas as pd
import streamlit as st
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import HttpRequest
from dateutil import tz

SCOPE = "https://www.googleapis.com/auth/spreadsheets"
SPREADSHEET_ID = "1Ym2nbTDvApMRUErsPoT4frr_-6TAZY2gzrX2sfgaWLg"
GSHEET_URL = f"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}"
SHEET_NAME = ["Database", "reaction"]
timezone = tz.tzlocal()


@st.experimental_singleton(show_spinner=False, suppress_st_warning=True) #êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
def connect_to_gsheet():
    # Create a connection object.
    credentials = service_account.Credentials.from_service_account_info(
        st.secrets["gcp_service_account"],
        scopes=[SCOPE],
    )
    # Create a new Http() object for every request
    def build_request(http, *args, **kwargs):
        new_http = google_auth_httplib2.AuthorizedHttp(
            credentials, http=httplib2.Http()
        )
        return HttpRequest(new_http, *args, **kwargs)

    authorized_http = google_auth_httplib2.AuthorizedHttp(
        credentials, http=httplib2.Http()
    )
    service = build(
        "sheets",
        "v4",
        requestBuilder=build_request,
        http=authorized_http,
    )
    gsheet_connector = service.spreadsheets()
    return gsheet_connector


def get_data(gsheet_connector) -> pd.DataFrame:
    values = (
        gsheet_connector.values()
        .get(
            spreadsheetId=SPREADSHEET_ID,
            range=f"{SHEET_NAME[0]}!A:C",
        )
        .execute()
    )

    df = pd.DataFrame(values["values"])
    df.columns = df.iloc[0]
    df = df[1:]
    return df


def add_row_to_gsheet(gsheet_connector, row) -> None:
    gsheet_connector.values().append(
        spreadsheetId=SPREADSHEET_ID,
        range=f"{SHEET_NAME[0]}!A:B",
        body=dict(values=row),
        valueInputOption="USER_ENTERED",
    ).execute()
    
def random_emoji():
    emojis = ["ğŸ’–","ğŸ§¡","ğŸ’›","ğŸ’š","ğŸ’™","ğŸ’œ","ğŸ¤","ğŸ–¤"]  
    st.session_state.emoji = random.choice(emojis)

gsheet_connector = connect_to_gsheet()

headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'}


#ì „ì²´ í˜ì´ì§€
st.set_page_config(page_title="ì²™ì²™ ì„ë°•ì˜ ê¸°ì‚¬ ì¸ìš© ë„ìš°ë¯¸",          
    page_icon="ğŸ‘€",
    layout="wide",
    initial_sidebar_state="auto",
    menu_items={
        'Get Help': 'https://github.com/LAB-703',
        'Report a bug': "https://github.com/LAB-703",
        'About': '''SPDX-FileCopyrightText: Â© 2022 LAB-703 SPDX-License-Identifier: MIT'''
    }
)

#ì „ì²´ í°íŠ¸ 

st.markdown("""
        <style>
@font-face {
  font-family: 'Pretendard';
  font-style: normal;
  font-weight: 800;
  src: url(https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard-dynamic-subset.css) format('woff');
}
    html, body, [class*="css"]  {
    font-family: 'Pretendard';
    font-size: 20px;
    }
    </style>""",unsafe_allow_html=True)

#ë²„íŠ¼
st.markdown("""
<style>
div.stButton > button:first-child {
  font-family: 'Pretendard';
  font-size:70%;
    background-color: #FCF9F6;
    font-color: #C0504D;
}
</style>""", unsafe_allow_html=True)

#st.markdown("""        <style>
#        
#@font-face {
#  font-family: 'Pretendard';
#  font-style: normal;
#  font-weight: 400;
#  src: url(https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css) format('woff');
#}
#    html, body, [class*="css"]  {
#    font-family: 'Pretendard';
#    font-size: 20px;
#    }
#    </style>""",unsafe_allow_html=True)

# ë©”ì¸ë©”ë‰´ ì—†ì• ê³ , ì €ì‘ê¶Œ í‘œì‹œ
hide_menu='''
<style>
#MainMenu {
    visibility:hidden;
}
footer {
    visibility:visible;
    size: 10%;
    font-family: 'Pretendard';
}
footer:after{
    content: 'SPDX-FileCopyrightText: Â© 2022 LAB-703 SPDX-License-Identifier: MIT';
    font-size: 15px;
    display:block;
    position:relative;
    color:silver;
    font-family: 'Pretendard';
}
</style>
'''
st.markdown(hide_menu, unsafe_allow_html=True)

select_event = st.sidebar.selectbox("ğŸˆ", ("ğŸ‘€ ê¸°ì‚¬ ì¸ìš© ë„ìš°ë¯¸", "ğŸ“œ í•™ìˆ ì§€ ëª©ë¡","ğŸ“Œ ê°œë°œ"))
if "emoji" not in st.session_state:
    st.session_state.emoji = "ğŸ¤"
st.sidebar.button(f" ì¢‹ì•„ìš” {st.session_state.emoji}", on_click=random_emoji)
#page1#######################################################################################################
if select_event == "ğŸ‘€ ê¸°ì‚¬ ì¸ìš© ë„ìš°ë¯¸":
    st.markdown('<p align="center" style=" font-size: 120%;"><b>ğŸ‘€ ì²™ì²™ ì„ë°•ë“¤ì„ ìœ„í•œ ê¸°ì‚¬ ì¸ìš© ë„ìš°ë¯¸</b></p>', unsafe_allow_html=True)

    URL=st.text_input("ë„¤ì´ë²„/ë‹¤ìŒ ë‰´ìŠ¤ urlì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    col1,col2=st.columns([5,5])  
    with col1:

        STYLE=st.radio("ì¸ìš© ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
             ("APA", 
              'CHICAGO',
              'by JOURNAL')) # : â³ ê°œë°œ ì¤‘'))        
        final_search=st.checkbox('ìµœì¢… ê²€ìƒ‰ì¼(ì˜¤ëŠ˜) ì¶”ê°€')
        submit=st.button('ì¸ìš©')
    with col2:
        if STYLE=="by JOURNAL":
            #st.markdown('<p style=" font-size: 100%; color:silver"> â³ê°œë°œ ì¤‘', unsafe_allow_html=True)
            journal_list=['Email', 'Home phone', 'Mobile phone']
            st.table(list(get_data(gsheet_connector)['í•™ìˆ ì§€']))
            option = st.selectbox('ì°¾ìœ¼ì‹œëŠ” í•™ìˆ ì§€ê°€ ìˆë‚˜ìš”?',journal_list)
            st.markdown('<p style=" font-size: 70%; color:silver"> í•™ìˆ ì§€ê°€ ì—†ë‹¤ë©´, ğŸ“œ í•™ìˆ ì§€ ëª©ë¡ í˜ì´ì§€ì—ì„œ ì¶”ê°€ì— ë™ì°¸í•´ ì£¼ì„¸ìš”.</p>', unsafe_allow_html=True)
            
    if submit==True:
#---------------------------------------------------------------------------------------------        
            if URL.find("n.news.naver.com/")>0: 
                req =requests.get(URL,headers=headers)
                html_doc = req.text  
                soup = bs(html_doc, 'html.parser')
                TITLE=soup.find("h2",{"class":"media_end_head_headline"}).get_text()
                DATE_write=soup.find("span",{"class":"media_end_head_info_datestamp_time _ARTICLE_DATE_TIME"}).get_text()[:10]
                #DATE_modify=soup.find("span",{"class":"media_end_head_info_datestamp_time _ARTICLE_MODIFY_DATE_TIME"}).get_text()[:10]
                
                AUTHOR=soup.find("em",{"class":"media_end_head_journalist_name"}).get_text().split()[0]
                COMPANY=soup.find("em",{"class":"media_end_linked_more_point"}).get_text()
            elif URL.find("v.daum.net/")>0 :
                    # header = {
                    #     'authority' : 'comment.daum.net',
                    #     'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36',
                    #     'accept' : "*/*",
                    #     'accept-encoding' : 'gzip, deflate, br',
                    #     'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
                    #     'referer' : URL,
                    #     }
                    html = requests.get(URL, headers = headers)
                    test_text= html.text  
                    soup = bs(test_text, 'html.parser')
                    DATE_write=soup.find("span",{"class":"num_date"}).get_text()[:12].replace(" ","")
                    COMPANY=soup.select_one('meta[property="og:article:author"]')['content']
                    TITLE=soup.find("h3",{"class":"tit_view"}).get_text()#.replace("\'",'"')
                    #--------------------ê¸°ì ì´ë¦„ 
                    if soup.find("span",{"class":"txt_info"}).get_text().startswith("ì…ë ¥")==True:
                        AUTHOR="" #ì—†ì„ ì‹œ ë¹ˆì¹¸
                    else: #ê¸°ìê°€ ë¶™ì–´ìˆìœ¼ë©´ ë–¼ê³ , ì•ì— ì–¸ë¡ ì‚¬ ë¶™ì–´ìˆìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬í•´ì„œ ë§ˆì§€ë§‰ í–‰ë§Œ ê°€ì ¸ì˜¤ë„ë¡ 
                        AUTHOR=soup.find("span",{"class":"txt_info"}).get_text().split()[0]
#---------------------------------------------------------------------------------------------------------
            else :
                st.error('ë§í¬ê°€ ì—†ê±°ë‚˜ ë„¤ì´ë²„/ë‹¤ìŒ í¬í„¸ë‰´ìŠ¤ì˜ ë§í¬ê°€ ì•„ë‹™ë‹ˆë‹¤!')
                st.stop()
            APA=AUTHOR+". "+"("+DATE_write+"). "+TITLE+". "+COMPANY+". "+URL
            CHICAGO=AUTHOR+', "'+TITLE+'" '+COMPANY+", "+DATE_write+", "+URL
            FINAL=str(datetime.now().astimezone(timezone).strftime("%Y.%m.%d."))
            if final_search==True:
                APA=APA+", ìµœì¢…ê²€ìƒ‰ì¼: "+FINAL
                CHICAGO=CHICAGO+", ìµœì¢…ê²€ìƒ‰ì¼: "+FINAL
            if STYLE=="APA":
                st.code(APA,language="Markdown")
                #clipboard.copy(APA)
                st.write('ì˜¤ë¥¸ìª½ ë³µì‚¬ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.')
            elif STYLE=="CHICAGO":
                st.code(CHICAGO,language="Markdown")
                #clipboard.copy(CHICAGO)
                st.write('ì˜¤ë¥¸ìª½ ë³µì‚¬ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.')
            else:
                st.markdown('<p style=" font-size: 100%; color:silver"> â³ê°œë°œ ì¤‘', unsafe_allow_html=True)
                

#page2#######################################################################################################     
if select_event == "ğŸ“œ í•™ìˆ ì§€ ëª©ë¡":
    #st.subheader("â³ ê°œë°œ ì¤‘")
    st.markdown('<p align="center" style=" font-size: 140%;"><b>ğŸ“œ ë“±ì¬ëœ í•™ìˆ ì§€ ëª©ë¡</b></p>', unsafe_allow_html=True)
    LIST=['Email', 'Home phone', 'Mobile phone']
    journallist = st.selectbox('',LIST)
    st.write("---")
    #st.write('í•™ìˆ ì§€ ì¶”ê°€ë¥¼ ì›í•˜ì‹ ë‹¤ë©´, ë”ë³´ê¸° ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.')
    expander = st.expander("í•™ìˆ ì§€ ì¶”ê°€ë¥¼ ì›í•˜ì‹ ë‹¤ë©´ í´ë¦­í•˜ì„¸ìš”.")
    journal=expander.text_input("ì¶”ê°€í•  í•™ìˆ ì§€ì˜ ì •ì‹ í•œê¸€ ëª…ì¹­ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    col1,col2=expander.columns([5,5])  
    with col1:
        st.markdown("[![Foo](https://www.kci.go.kr/kciportal/resources/newkci/image/kor/title/h1_logo.png)](https://www.kci.go.kr/kciportal/main.kci)")
    with col2:
        st.markdown('<p style=" font-size: 80%; color:silver"> ğŸ”í•™ìˆ ì§€ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>', unsafe_allow_html=True)
    dic = {'AUTHOR':'ê¸°ì',
       'TITLE': 'ê¸°ì‚¬ ì œëª©',
       'COMPANY': 'ì–¸ë¡ ì‚¬', 
       'DATE_write':'ê¸°ì‚¬ì‘ì„±ì¼',
       'URL' :'ê¸°ì‚¬ URL',
       'FINAL_SEARCH':'ìµœì¢…ê²€ìƒ‰ì¼',
           'COMMA':',',
           'LEFT':'(',
        'RIGHT':')',
          'DOT':'.'}
     
    multiselect= expander.multiselect('ìˆœì„œëŒ€ë¡œ ë†“ì•„ì£¼ì„¸ìš”.',
                                list(dic.values()), 
                                list(dic.values())[:2]) #default
    annotation=""
    for selection in multiselect:
        if selection in list(dic.values())[:6]:
            annotation+=selection+". "
        elif selection in list(dic.values())[6]:
            annotation+=selection+" "
        else :
            annotation+=selection
    expander.markdown(annotation)
    today=str(datetime.now().astimezone(timezone).strftime("%Y-%m-%d %H:%M:%S"))
    submitted = expander.button("ì¶”ê°€")
    if submitted:
        add_row_to_gsheet(
            gsheet_connector,
            [[journal, annotation,today]],
        )
        expander.success("ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‘€ ê¸°ì‚¬ ì¸ìš© ë„ìš°ë¯¸ í˜ì´ì§€ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        expander.balloons()
#page3#######################################################################################################
if select_event == "ğŸ“Œ ê°œë°œ":
    st.header("ğŸ‘©ğŸ»â€ğŸ’» ê°œë°œì")
    col1,col2=st.columns([3,7])
    with col1 :
        st.markdown('<a href="http://m.site.naver.com/0Z7nr"><img src="https://qrcodethumb-phinf.pstatic.net/20220702_173/1656698540984dDVVY_PNG/0Z7nr.png"/></a>', unsafe_allow_html=True)
    with col2 :
        st.markdown("<br>ê°œë°œìì—ê²Œ ì»¤í”¼ í•œì”ì€ í° í˜ì´ ë©ë‹ˆë‹¤â˜•ï¸<br>í›„ì›ì€ ìµëª…ìœ¼ë¡œ ê°€ëŠ¥í•©ë‹ˆë‹¤ğŸ­", unsafe_allow_html=True)
    st.markdown("---")
    st.header("ğŸ“† ê°œë°œ ê¸°ë¡")
    st.markdown("`ğŸ“Œ ë°°í¬ ì™„ë£Œ` `ğŸ ë²„ê·¸ ìˆ˜ì •`")
    beta1_0=st.expander("1ï¸âƒ£ 2022. 06. 28. beta 1.0 ë°°í¬")
    beta1_0.markdown('''<p align="left" style="font-size: 70%; text-indent : 20px;"> ğŸ“Œ ë„¤ì´ë²„/ë‹¤ìŒ ë‰´ìŠ¤ APA, CHICAGO ìŠ¤íƒ€ì¼ ì¸ìš© ê¸°ëŠ¥ ì¶”ê°€</p>''', unsafe_allow_html=True)
    beta2_0=st.expander("1ï¸âƒ£ 2022. 07. 02. beta 2.0 ë°°í¬")
    beta2_0.markdown('''<p align="left" style="font-size: 70%; text-indent : 20px;"> ğŸ íƒ€ì„ì¡´ UTC â†’ KST ìˆ˜ì • </p>''', unsafe_allow_html=True)
    beta2_0.markdown('''<p align="left" style="font-size: 70%; text-indent : 20px;"> ğŸ“Œ ê°œë°œì ì»¤í”¼ í›„ì› ê¸°ëŠ¥ ì¶”ê°€ </p>''', unsafe_allow_html=True)
    
    
    
#    #ì¦ê²¨ì°¾ê¸° ì¶”ê°€ì¸ë° ìœˆë„ìš°ì—ì„œë§Œ ë¨¹í˜€
#    a='''
#    <a href="JavaScript:window.external.AddFavorite('https://blog.naver.com/hyoyeol/70152225558','ëŠ‘ëŒ€í„¸ì“´ì–‘ í™ˆí˜ì´ì§€')">
#    '''
#    st.markdown(a)
#    st.markdown("[![Foo](https://postfiles.pstatic.net/MjAyMjA2MjZfOTgg/MDAxNjU2MjM0OTkwMjU5.OGRjH6YMCvGKy6AtjnTDjbGh-3MVP5yUsQmKHTlljNsg.6qk6L05rB42FP4F7P5M-TsF4gzRLKI23hIHBv_aW0nkg.PNG.faraway10/SE-f1959757-e2c6-4df0-85a5-1f2987b88c5d.png?type=w773)](https://postfiles.pstatic.net/MjAyMjA2MjZfMzYg/MDAxNjU2MjM1MDM1NDUz.hDsSoeeQATTXFBzlJ9DKBLoYS5rrYTLm8WekqElLNDAg.WqSp45bEruil_YHoScx-y_ZcF1t6Rub4DtJ7ObGGLiAg.PNG.faraway10/SE-9886a95b-a8ad-4edb-99b5-78bff09acb9d.png?type=w773)")

####################
